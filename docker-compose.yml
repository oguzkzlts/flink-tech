volumes:
  kafka-data:
  zookeeper-data:

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    volumes:
      - zookeeper-data:/var/lib/zookeeper
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 5s
      timeout: 5s
      retries: 10

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
    ports:
      - "29092:29092"
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka:9092 --list || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 20

  jobmanager:
    image: flink:1.20.1
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      JOB_MANAGER_RPC_ADDRESS: jobmanager
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 5s
      timeout: 10s
      retries: 10

  taskmanager:
    image: flink:1.20.1
    command: taskmanager
    depends_on:
      jobmanager:
        condition: service_healthy
    environment:
      JOB_MANAGER_RPC_ADDRESS: jobmanager
      TASK_MANAGER_NUMBER_OF_TASK_SLOTS: "1"
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -i '[t]askmanager' || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 10

  kafka-topic-creator:
    image: confluentinc/cp-kafka:7.0.1
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint:
      - sh
      - -c
      - |
        # 1. Wait for Kafka (with timeout)
        timeout 60 bash -c '
          until kafka-topics --bootstrap-server kafka:9092 --list >/dev/null 2>&1; do
            echo "Waiting for Kafka metadata service..."
            sleep 2
          done
        ' || { echo "ERROR: Kafka timeout"; exit 1; }

        # 2. Create topics with forced timeouts
        timeout 30 kafka-topics --bootstrap-server kafka:9092 \
          --create --if-not-exists \
          --topic crypto-prices --partitions 1 --replication-factor 1 || \
          { echo "ERROR: Failed to create crypto-prices"; exit 1; }

        timeout 30 kafka-topics --bootstrap-server kafka:9092 \
          --create --if-not-exists \
          --topic alerts --partitions 1 --replication-factor 1 || \
          { echo "ERROR: Failed to create alerts"; exit 1; }

        # 3. Final verification (optional)
        timeout 10 kafka-topics --bootstrap-server kafka:9092 --list
        echo "Topics ready at $(date)"

        # 4. Explicit success exit (prevent hangs)
        exit 0

  flink-job:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      kafka-topic-creator:
        condition: service_completed_successfully
      jobmanager:
        condition: service_healthy
      taskmanager:
        condition: service_healthy
    command:
      - sh
      - -c
      - |
        echo "Starting Flink job..."
        /opt/flink/bin/flink run \
          -m jobmanager:8081 \
          -c org.example.flink.KafkaStreamingJob \
          /opt/flink/usrlib/FlinkTech-1.0-SNAPSHOT.jar
        
        # Keep container running to view logs
        tail -f /dev/null